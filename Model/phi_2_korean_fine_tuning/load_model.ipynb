{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bad1ea9-bd1c-46a6-9196-31c1fb14f384",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T08:51:04.502168Z",
     "iopub.status.busy": "2024-04-04T08:51:04.500910Z",
     "iopub.status.idle": "2024-04-04T08:51:24.919349Z",
     "shell.execute_reply": "2024-04-04T08:51:24.917567Z",
     "shell.execute_reply.started": "2024-04-04T08:51:04.502059Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    GenerationConfig\n",
    ")\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21f47a81-a90b-4711-87fe-85f75da61b59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T08:51:30.493371Z",
     "iopub.status.busy": "2024-04-04T08:51:30.491295Z",
     "iopub.status.idle": "2024-04-04T08:51:30.510840Z",
     "shell.execute_reply": "2024-04-04T08:51:30.508338Z",
     "shell.execute_reply.started": "2024-04-04T08:51:30.493220Z"
    }
   },
   "outputs": [],
   "source": [
    "compute_dtype = getattr(torch, \"float16\")\n",
    "#모델을 4bit 형식으로 로드(메모리 소비가 줄어듦)\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type='nf4',\n",
    "        bnb_4bit_compute_dtype=compute_dtype,\n",
    "        bnb_4bit_use_double_quant=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8912607-a431-4217-9182-4b214cdaf2b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T08:51:31.915357Z",
     "iopub.status.busy": "2024-04-04T08:51:31.913983Z",
     "iopub.status.idle": "2024-04-04T08:52:06.464147Z",
     "shell.execute_reply": "2024-04-04T08:52:06.463112Z",
     "shell.execute_reply.started": "2024-04-04T08:51:31.915249Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/gatoai/python/venv/3.10/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:466: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24530bb619f24d89aa97dab041f9104e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "base_model_id = \"microsoft/phi-2\"\n",
    "base_model = AutoModelForCausalLM.from_pretrained(base_model_id, \n",
    "                                                      device_map='auto',\n",
    "                                                      quantization_config=bnb_config,\n",
    "                                                      trust_remote_code=True,\n",
    "                                                      use_auth_token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a8108bf-5bac-4d3e-8d59-b0df8376c523",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T08:53:12.620097Z",
     "iopub.status.busy": "2024-04-04T08:53:12.617802Z",
     "iopub.status.idle": "2024-04-04T08:53:12.628261Z",
     "shell.execute_reply": "2024-04-04T08:53:12.626352Z",
     "shell.execute_reply.started": "2024-04-04T08:53:12.620006Z"
    }
   },
   "outputs": [],
   "source": [
    "# tokenizer_ko = AutoTokenizer.from_pretrained(\"EleutherAI/polyglot-ko-5.8b\",trust_remote_code=True,padding_side=\"right\", padding=True,add_eos_token=True,add_bos_token=True,use_fast=False)\n",
    "#     #tokenizer.pad_token = tokenizer.eos_token: 이 부분은 패딩 토큰을 EOS (End-Of-Sequence) 토큰으로 설정합니다. 이렇게 하면 모델이 패딩을 식별하는 데 사용되는 토큰을 EOS 토큰으로 사용하게 됩니다.\n",
    "# tokenizer_ko.pad_token = tokenizer_ko.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7d0eaf3-184c-41ad-85da-6523e6e54228",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T08:53:16.932121Z",
     "iopub.status.busy": "2024-04-04T08:53:16.930112Z",
     "iopub.status.idle": "2024-04-04T08:53:17.822498Z",
     "shell.execute_reply": "2024-04-04T08:53:17.821810Z",
     "shell.execute_reply.started": "2024-04-04T08:53:16.932030Z"
    }
   },
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "# is_trainable=False여기서는 이 PEFT 모델로만 추론을 수행할 계획이므로 설정\n",
    "ft_model = PeftModel.from_pretrained(base_model, \"./model/peft-ko-training-1712189085/checkpoint-1000/\",torch_dtype=torch.float16,is_trainable=False)\n",
    "\n",
    "#미세 조정은 종종 반복적인 프로세스입니다. \n",
    "#검증 및 테스트 세트 결과에 따라 성능을 향상시키기 위해 \n",
    "#모델의 아키텍처, 하이퍼파라미터 또는 교육 데이터를 추가로 조정해야 할 수도 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c01de08-b5d4-4833-8128-188236318976",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T08:53:20.018310Z",
     "iopub.status.busy": "2024-04-04T08:53:20.015965Z",
     "iopub.status.idle": "2024-04-04T08:53:26.077800Z",
     "shell.execute_reply": "2024-04-04T08:53:26.075846Z",
     "shell.execute_reply.started": "2024-04-04T08:53:20.018193Z"
    }
   },
   "outputs": [],
   "source": [
    "huggingface_dataset_name = \"beomi/KoAlpaca-v1.1a\"\n",
    "#data set load\n",
    "dataset = load_dataset(huggingface_dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbb11664-84fe-4ffa-93ec-e1981d2a17ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T08:53:28.472241Z",
     "iopub.status.busy": "2024-04-04T08:53:28.470870Z",
     "iopub.status.idle": "2024-04-04T08:53:28.876623Z",
     "shell.execute_reply": "2024-04-04T08:53:28.876032Z",
     "shell.execute_reply.started": "2024-04-04T08:53:28.472155Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "def tokenizer_fun(tokenizer_name):\n",
    "    '''\n",
    "        토크나이저를 설정하는 함수\n",
    "    '''\n",
    "    tokenizer_ko = AutoTokenizer.from_pretrained(\"EleutherAI/polyglot-ko-5.8b\",trust_remote_code=True,padding_side=\"right\", padding=True,add_eos_token=True,add_bos_token=True,use_fast=False)\n",
    "    #tokenizer.pad_token = tokenizer.eos_token: 이 부분은 패딩 토큰을 EOS (End-Of-Sequence) 토큰으로 설정합니다. 이렇게 하면 모델이 패딩을 식별하는 데 사용되는 토큰을 EOS 토큰으로 사용하게 됩니다.\n",
    "    tokenizer_ko.pad_token = tokenizer_ko.eos_token\n",
    "\n",
    "    return tokenizer_ko\n",
    "\n",
    "tokenizer_ko = tokenizer_fun('EleutherAI/polyglot-ko-5.8b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b755fe8-913b-4253-a465-82d1a59bb73a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T08:53:31.672617Z",
     "iopub.status.busy": "2024-04-04T08:53:31.671238Z",
     "iopub.status.idle": "2024-04-04T08:53:31.684837Z",
     "shell.execute_reply": "2024-04-04T08:53:31.682809Z",
     "shell.execute_reply.started": "2024-04-04T08:53:31.672532Z"
    }
   },
   "outputs": [],
   "source": [
    "def gen(model_name, prompt, max_length):\n",
    "    # 입력 텍스트를 토크나이즈하고 모델에 입력할 형식으로 변환\n",
    "    input_ids = tokenizer_ko.encode(prompt, max_length=max_length, padding=True, return_tensors=\"pt\", truncation=True, return_attention_mask=True)\n",
    "    \n",
    "    # 모델에 입력하여 텍스트 생성\n",
    "    outputs = model_name.generate(input_ids.to('cuda'), max_length=max_length,pad_token_id=tokenizer_ko.eos_token_id)\n",
    "\n",
    "    # print(len(outputs))\n",
    "    # print(outputs)\n",
    "    \n",
    "    \n",
    "    # 생성된 텍스트 디코딩\n",
    "    generated_text = tokenizer_ko.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c5332254-302a-49dd-a0e2-c674dcfe69c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T09:21:26.352706Z",
     "iopub.status.busy": "2024-04-04T09:21:26.351517Z",
     "iopub.status.idle": "2024-04-04T09:21:26.376653Z",
     "shell.execute_reply": "2024-04-04T09:21:26.374759Z",
     "shell.execute_reply.started": "2024-04-04T09:21:26.352549Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_prompt_formats(sample):\n",
    "    \"\"\"\n",
    "    Format various fields of the sample ('instruction','output')\n",
    "    Then concatenate them using two newline characters \n",
    "    :param sample: Sample dictionnary\n",
    "    \"\"\"\n",
    "    INTRO_BLURB = \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\"\n",
    "    INSTRUCTION_KEY = \"### Instruct: Answer the questions below\"\n",
    "    RESPONSE_KEY = \"### Output:\"\n",
    "    END_KEY = \"### End\"\n",
    "    \n",
    "    blurb = f\"\\n{INTRO_BLURB}\"\n",
    "    instruction = f\"{INSTRUCTION_KEY}\"\n",
    "    input_context = f\"{sample['instruction']}\" if sample[\"instruction\"] else None\n",
    "    response = f\"{RESPONSE_KEY}\\n\"\n",
    "    # end = f\"{END_KEY}\"\n",
    "    \n",
    "    parts = [part for part in [blurb, instruction, input_context, response] if part]\n",
    "\n",
    "    formatted_prompt = \"\\n\\n\".join(parts)\n",
    "    sample[\"text\"] = formatted_prompt\n",
    "\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "48995734-6921-49e4-bf8c-ae5cd0ad4c2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T09:31:20.725188Z",
     "iopub.status.busy": "2024-04-04T09:31:20.724024Z",
     "iopub.status.idle": "2024-04-04T09:31:53.991054Z",
     "shell.execute_reply": "2024-04-04T09:31:53.989495Z",
     "shell.execute_reply.started": "2024-04-04T09:31:20.725115Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': \"'땡추가 뭐예요?'라는 말이 무슨 뜻인가요? 이 말의 유래와 역사적인 배경을 알려주세요.\", 'output': \"'땡추'는 원래 고려시대에 개혁을 추진한 몽골의 지배에 벗어나고자 노력한 스님들의 모임입니다. 그러나 조선시대 불교 탄압으로 인해 '땡추'라는 단어는 부정적인 의미로 바뀌었으며, '땡중'이라는 단어로 파생되어 술과 고기를 즐기고 수행에 관심이 없는 스님들을 비아냥하는 뜻으로 쓰이기도 합니다. 땡추는 전국적으로 조직화 되어 있었고, 부당한 대우나 형편에 처한 경우 서로 돕고 오랜 조직원 가운데 어떤 사람이 저지른 실수나 곤란한 일을 당하면 반드시 복수하는 등 자체 법집을 갖추고 있었습니다. 이러한 역사적인 배경을 갖고 있어, '땡추가 뭐예요?'라고 하는 것은 불친절한 말이기 때문에 조심해야 합니다.\", 'url': 'https://kin.naver.com/qna/detail.naver?d1id=6&dirId=613&docId=61653563'}\n",
      "---------------------------------------------------------------------------------------------------\n",
      "\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruct: Answer the questions below\n",
      "\n",
      "'땡추가 뭐예요?'라는 말이 무슨 뜻인가요? 이 말의 유래와 역사적인 배경을 알려주세요.\n",
      "\n",
      "### Output:\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "'땡추가 뭐예요?'라는 말이 무슨 뜻은 말의 유래와 역사적인 배경을 알려주세요. 이 말의 유래와 역사적인 배경을 알려주세요. 이 말의 유래와 역사적인 배경을 알려주세요. 이 말의 유래와 역사적인 배경을 알려주세요. 이 말의 유래와 역사적인 배경을 알려주세요. 이 말의 유래와 역사적인 배경을 알려주세요. 이 말의 유래와 역사적인 배경을 알려주세요. 이 말의 유래와 역사적인 배경을 알려주세요. 이 말의 유래와 역사적인 배경을 알려주세요.\n",
      "\n",
      "### End. 이 말의 유래와 역사적인 배경을 알려주세요. 이 말의 유래와 역사적인 배경을 알려주세요. 이 말의 유래와 역사적인 배경을 알려주세요. 이 말의 유래와 역사적인 배경을 알려주세요. 이 말의 유래와 역사적인 배경을 알려주세요. 이 말의 유래와 역사적인 배경을 알려주세요.\n",
      "\n",
      "### End. 이 말의 유래와 역사적인 배경을 알려주세요. 이 말의 유래와 역사적인 배경을 알려주세요. 이 말의 유래와 역사적인 배경을 알려주세요. 이 말의 유래와 역사적인 배경을 알려주세요. 이 말의 유래와 역사적인 배경을 알려주세요. 이 말의 유래와 역사적인 배경을 알려주세요. 이 말의 유래와 역사적인 배경을 알려주세요. 이 말의 유래와 역사적인 배경을 알려주세요. 이 말의 유래와 역사적인 배경을 알려주세요.\n",
      "\n",
      "### End. 이 말의 유래와 역사적인 배경을 알려주세요. 이 말의 유래와 역사적인 배경을 알려주세요. 이 말의 유래와 역사적인 배경을 알려주세요. 이 말의 유래와 역사적인 배경을 알려주세요. 이 말의 유래\n",
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "'땡추가 뭐예요?'라는 말이 무슨 뜻인가요? 이 말의 유래와 역사적인 배경을 알려주세요.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "'땡추'는 원래 고려시대에 개혁을 추진한 몽골의 지배에 벗어나고자 노력한 스님들의 모임입니다. 그러나 조선시대 불교 탄압으로 인해 '땡추'라는 단어는 부정적인 의미로 바뀌었으며, '땡중'이라는 단어로 파생되어 술과 고기를 즐기고 수행에 관심이 없는 스님들을 비아냥하는 뜻으로 쓰이기도 합니다. 땡추는 전국적으로 조직화 되어 있었고, 부당한 대우나 형편에 처한 경우 서로 돕고 오랜 조직원 가운데 어떤 사람이 저지른 실수나 곤란한 일을 당하면 반드시 복수하는 등 자체 법집을 갖추고 있었습니다. 이러한 역사적인 배경을 갖고 있어, '땡추가 뭐예요?'라고 하는 것은 불친절한 말이기 때문에 조심해야 합니다.\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "PEFT MODEL:\n",
      "'땡추가 뭐예요?'라는 말이 무슨 뜻은 말의 유래와 역사적인 배경을 알려주세요. 이 말의 유래와 역사적인 배경을 알려주세요. 이 말의 유래와 역사적인 배경을 알려주세요. 이 말의 유래와 역사적인 배경을 알려주세요. 이 말의 유래와 역사적인 배경을 알려주세요. 이 말의 유래와 역사적인 배경을 알려주세요. 이 말의 유래와 역사적인 배경을 알려주세요. 이 말의 유래와 역사적인 배경을 알려주세요. 이 말의 유래와 역사적인 배경을 알려주세요.\n",
      "\n",
      "\n",
      "CPU times: user 33 s, sys: 162 ms, total: 33.2 s\n",
      "Wall time: 33.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## 인간 평가 방법\n",
    "from transformers import set_seed\n",
    "seed = 42\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "\n",
    "\n",
    "set_seed(seed)\n",
    "\n",
    "index = 20000\n",
    "sample = dataset['train'][index]\n",
    "# sample = {\"instruction\": '애국가 불러줘'}\n",
    "print(sample)\n",
    "print(dash_line)\n",
    "prompt = create_prompt_formats(sample)\n",
    "\n",
    "print(prompt['text'])\n",
    "\n",
    "#원래 모델을 사용하여 수행한 것처럼 동일한 입력을 사용하지만 PEFT 모델을 사용하여 추론을 수행\n",
    "peft_model_res = gen(ft_model,prompt['text'],550)\n",
    "peft_model_output = peft_model_res.split('Output:\\n')[1]\n",
    "print(dash_line)\n",
    "print(peft_model_output)\n",
    "prefix, success, result = peft_model_output.partition('###')\n",
    "\n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{prompt[\"instruction\"]}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{prompt[\"output\"]}\\n')\n",
    "print(dash_line)\n",
    "print(f'PEFT MODEL:\\n{prefix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89a396c9-956b-437f-8057-af87619386d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T12:59:52.864455Z",
     "iopub.status.busy": "2024-03-24T12:59:52.863399Z",
     "iopub.status.idle": "2024-03-24T13:00:17.520000Z",
     "shell.execute_reply": "2024-03-24T13:00:17.517995Z",
     "shell.execute_reply.started": "2024-03-24T12:59:52.864321Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 미치ruction' :\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction\n",
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "Instruction:\n",
      "스웨터의 유래는 어디에서 시작되었나요?\n",
      "Output:\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "스웨터의 유래는 14세기경 북유럽항구지역에서 어망을 짜던 기술을 의복에 활용하면서 시작되었습니다. 노동자들의 방한복에서 시작된 스웨터는 여가생활과 스포츠의 붐에 힘입어 대중화되었습니다. 이후, 겨울철 이너웨어의 대명사가 되었습니다. 스웨터는 짜서(Knit) 만든 옷을 말하며, 어부들의 방한복으로 짜여졌던 스웨터 중에서도 스코틀랜드 해안지방의 여인들은 바다로 나가는 남편이나 연인, 자식들에게 무사히 돌아올 것을 기원하며 로프나 닻 무늬를 정성껏 짜넣었다고 합니다. 그 실용성과 정성이 오늘에까지 이어지고 있습니다.\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "PEFT MODEL:\n",
      " 미치ruction' :\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction:\n",
      "Out:\n",
      " 미치ruction\n",
      "CPU times: user 24.5 s, sys: 89.3 ms, total: 24.6 s\n",
      "Wall time: 24.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## 인간 평가 방법\n",
    "from transformers import set_seed\n",
    "seed = 42\n",
    "\n",
    "set_seed(seed)\n",
    "\n",
    "index = 1\n",
    "instruction = dataset['train'][index]['instruction']\n",
    "output = dataset['train'][index]['output']\n",
    "\n",
    "prompt = f\"Instruction:\\n{instruction}\\nOutput:\\n\"\n",
    "\n",
    "#원래 모델을 사용하여 수행한 것처럼 동일한 입력을 사용하지만 PEFT 모델을 사용하여 추론을 수행\n",
    "peft_model_res = gen(ft_model,prompt,350)\n",
    "peft_model_output = peft_model_res.split('Output:\\n')[1]\n",
    "print(peft_model_output)\n",
    "prefix, success, result = peft_model_output.partition('###')\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{prompt}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{output}\\n')\n",
    "print(dash_line)\n",
    "print(f'PEFT MODEL:\\n{prefix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "21c22136-5c91-4b49-a27c-147bae94a29b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T13:00:49.863314Z",
     "iopub.status.busy": "2024-03-24T13:00:49.862485Z",
     "iopub.status.idle": "2024-03-24T13:01:15.013065Z",
     "shell.execute_reply": "2024-03-24T13:01:15.010621Z",
     "shell.execute_reply.started": "2024-03-24T13:00:49.863237Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below 그냥ruction:Below 그냥ruction' \"'se'i 이름:\n",
      "Out:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "Instruction:\n",
      "너의 이름은 뭐야?\n",
      "Output:\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "양파는 잎이 아닌 식물의 줄기 부분입니다. 고구마는 식물의 뿌리 부분입니다. \n",
      "\n",
      "식물의 부위의 구분에 대해 궁금해하는 분이라면 분명 이 질문에 대한 답을 찾고 있을 것입니다. 양파는 잎이 아닌 줄기 부분입니다. 고구마는 다른 질문과 답변에서 언급된 것과 같이 뿌리 부분입니다. 따라서, 양파는 식물의 줄기 부분이 되고, 고구마는 식물의 뿌리 부분입니다.\n",
      "\n",
      " 덧붙이는 답변: 고구마 줄기도 볶아먹을 수 있나요? \n",
      "\n",
      "고구마 줄기도 식용으로 볶아먹을 수 있습니다. 하지만 줄기 뿐만 아니라, 잎, 씨, 뿌리까지 모든 부위가 식용으로 활용되기도 합니다. 다만, 한국에서는 일반적으로 뿌리 부분인 고구마를 주로 먹습니다.\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "PEFT MODEL:\n",
      "Below 그냥ruction:Below 그냥ruction' \"'se'i 이름:\n",
      "Out:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "Below 그냥ruction:\n",
      "CPU times: user 25 s, sys: 87.7 ms, total: 25.1 s\n",
      "Wall time: 25.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## 인간 평가 방법\n",
    "from transformers import set_seed\n",
    "seed = 42\n",
    "\n",
    "set_seed(seed)\n",
    "\n",
    "index = 0\n",
    "instruction = dataset['train'][index]['instruction']\n",
    "output = dataset['train'][index]['output']\n",
    "\n",
    "prompt = f\"Instruction:\\n너의 이름은 뭐야?\\nOutput:\\n\"\n",
    "\n",
    "#원래 모델을 사용하여 수행한 것처럼 동일한 입력을 사용하지만 PEFT 모델을 사용하여 추론을 수행\n",
    "peft_model_res = gen(ft_model,prompt,350)\n",
    "peft_model_output = peft_model_res.split('Output:\\n')[1]\n",
    "print(peft_model_output)\n",
    "prefix, success, result = peft_model_output.partition('###')\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{prompt}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{output}\\n')\n",
    "print(dash_line)\n",
    "print(f'PEFT MODEL:\\n{prefix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "237ecafe-4f9f-4b33-8ad1-85057a59e3d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T13:03:12.464788Z",
     "iopub.status.busy": "2024-03-24T13:03:12.463662Z",
     "iopub.status.idle": "2024-03-24T13:03:36.545299Z",
     "shell.execute_reply": "2024-03-24T13:03:36.544154Z",
     "shell.execute_reply.started": "2024-03-24T13:03:12.464710Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "충전기에 꼽다 아니면 꽂다깔 어느 것을 사용 하나요? 급합니다! (내공 90:\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "Instruction:\n",
      "충전기에 꼽다 아니면 꽂다 중 어느 것을 사용해야 하나요? 급합니다! (내공 90)\n",
      "Output:\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "꼽다와 꽂다는 많은 사람들이 헷갈려하는 단어입니다. 하지만 이 둘을 구분하는 방법이 있습니다. \"꼽다\"는 수나 날짜 등을 세려고 손가락을 헤아릴 때 사용하고, \"꽂다\"는 쓰러지지 않게 세우거나 고정할 때 사용합니다. 따라서 충전기를 콘센트에 연결할 때는 \"꽂다\"라는 표현을 사용하면 됩니다.\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "PEFT MODEL:\n",
      "충전기에 꼽다 아니면 꽂다깔 어느 것을 사용 하나요? 급합니다! (내공 90:\n",
      "\n",
      "CPU times: user 23.9 s, sys: 72.3 ms, total: 24 s\n",
      "Wall time: 24.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## 인간 평가 방법\n",
    "from transformers import set_seed\n",
    "seed = 42\n",
    "\n",
    "set_seed(seed)\n",
    "\n",
    "index = 100\n",
    "instruction = dataset['train'][index]['instruction']\n",
    "output = dataset['train'][index]['output']\n",
    "\n",
    "prompt = f\"Instruction:\\n{instruction}\\nOutput:\\n\"\n",
    "\n",
    "#원래 모델을 사용하여 수행한 것처럼 동일한 입력을 사용하지만 PEFT 모델을 사용하여 추론을 수행\n",
    "peft_model_res = gen(ft_model,prompt,350)\n",
    "peft_model_output = peft_model_res.split('Output:\\n')[1]\n",
    "print(peft_model_output)\n",
    "prefix, success, result = peft_model_output.partition('###')\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{prompt}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{output}\\n')\n",
    "print(dash_line)\n",
    "print(f'PEFT MODEL:\\n{prefix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a477ee6e-1e22-4214-b07c-08d1e1e6f547",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T13:04:33.829612Z",
     "iopub.status.busy": "2024-03-24T13:04:33.828573Z",
     "iopub.status.idle": "2024-03-24T13:04:58.232738Z",
     "shell.execute_reply": "2024-03-24T13:04:58.231582Z",
     "shell.execute_reply.started": "2024-03-24T13:04:33.829541Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "피 늘 감elbelow 그냥below 그냥belelow 그냥below 그냥belelow 그냥belelow 그냥belelow 그냥belelow 그냥belelow 그냥belelow 그냥belelow 그냥belelow 그냥belelow 그냥belelow 그냥belelow 그냥belelow 그냥belelelow 그냥belelelow 그냥belelelow 그냥belelelow 그냥belelelow 그냥belelelow 그냥belelelow 그냥belelelow 그냥belelelow 그냥belelelow 그냥belelelelow 그냥belelelow 그냥belelelelow 그냥belelelow 그냥belelelow 그냥belelelow 그냥belelelow 그냥belelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelel\n",
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "Instruction:\n",
      "피그말리온 효과란 무엇인가요? 구체적인 예시를 들어 설명해주세요.\n",
      "Output:\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "피그말리온 효과는 교사나 학부모 등 다른 사람의 높은 기대나 기대에 부응하기 위해 노력하는 개인이 그 기대를 충족시키는 현상을 말합니다. 이는 자기충족 예언이나 자성적 예언이라고도 불립니다. 우리가 상대방에게 가진 기대에 따라 그 사람의 행동 및 성과가 결정될 수 있습니다. 예를 들어, 교사가 한 학생에 대해 \"우리 학급에서 가장 똑똑한 아이다\" 라는 기대를 가지면 그 학생은 학급 내 다른 아이들보다 더 뛰어난 성과를 보일 가능성이 큽니다. 이는 교사나 학부모 등 다른 사람의 기대가 학생에 대해 무의식적으로 작용하기 때문입니다. 피그말리온 효과와 비슷한 효과로는 자기충족 예언, Placebo 효과, Hawthorn 효과, Merton의 예화, B. Show의 \"꽃파는 소녀∼\", Allport의 전쟁 기대 이론 등이 있습니다.\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "PEFT MODEL:\n",
      "피 늘 감elbelow 그냥below 그냥belelow 그냥below 그냥belelow 그냥belelow 그냥belelow 그냥belelow 그냥belelow 그냥belelow 그냥belelow 그냥belelow 그냥belelow 그냥belelow 그냥belelow 그냥belelow 그냥belelelow 그냥belelelow 그냥belelelow 그냥belelelow 그냥belelelow 그냥belelelow 그냥belelelow 그냥belelelow 그냥belelelow 그냥belelelow 그냥belelelelow 그냥belelelow 그냥belelelelow 그냥belelelow 그냥belelelow 그냥belelelow 그냥belelelow 그냥belelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelel\n",
      "CPU times: user 24.2 s, sys: 69.4 ms, total: 24.3 s\n",
      "Wall time: 24.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## 인간 평가 방법\n",
    "from transformers import set_seed\n",
    "seed = 42\n",
    "\n",
    "set_seed(seed)\n",
    "\n",
    "index = 300\n",
    "instruction = dataset['train'][index]['instruction']\n",
    "output = dataset['train'][index]['output']\n",
    "\n",
    "prompt = f\"Instruction:\\n{instruction}\\nOutput:\\n\"\n",
    "\n",
    "#원래 모델을 사용하여 수행한 것처럼 동일한 입력을 사용하지만 PEFT 모델을 사용하여 추론을 수행\n",
    "peft_model_res = gen(ft_model,prompt,350)\n",
    "peft_model_output = peft_model_res.split('Output:\\n')[1]\n",
    "print(peft_model_output)\n",
    "prefix, success, result = peft_model_output.partition('###')\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{prompt}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{output}\\n')\n",
    "print(dash_line)\n",
    "print(f'PEFT MODEL:\\n{prefix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "460b3bb6-9fbc-4ef5-b465-cfc79c96c56c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T13:05:21.580206Z",
     "iopub.status.busy": "2024-03-24T13:05:21.579340Z",
     "iopub.status.idle": "2024-03-24T13:05:45.795406Z",
     "shell.execute_reply": "2024-03-24T13:05:45.793684Z",
     "shell.execute_reply.started": "2024-03-24T13:05:21.580127Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uow 그냥belelbelelbelow 그냥belelbelow 그냥belelbelelbelow 그냥belelbelelow 그냥belelelbelow 그냥belelelow 그냥belelelbelow 그냥belelelelow 그냥belelelelow 그냥belelelow 그냥belelelow 그냥belelelow 그냥belelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelel\n",
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "Instruction:\n",
      "왜 utp선은 꼬여 있을까요?\n",
      "UTP선 보면 꼬여 있는데 그 이유가 무엇인가요?\n",
      "Output:\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "UTP케이블을 제작할 때, 케이블의 양쪽 끝의 배열이 동일하지 않으면 1~2미터 짧은 거리에서는 작동할 수 있지만, 전송률을 높이고 외부 전기 노이즈의 영향을 최소화 하기 위해 와이어가 꼬여 있어야 합니다. UTP케이블의 1, 2번은 TX(송신측), 3, 6번은 RX(수신측)이므로 꼬여 있다면 두 선의 밀착을 유지할 수 있습니다. 꼬여 있지 않은 경우, 랜카드의 LED도 작동하지 않고, 인터넷에 접속할 수 없습니다. 그러므로, UTP선은 왜 꼬여 있는지 명확하게 알아두는 것이 중요합니다.\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "PEFT MODEL:\n",
      "Uow 그냥belelbelelbelow 그냥belelbelow 그냥belelbelelbelow 그냥belelbelelow 그냥belelelbelow 그냥belelelow 그냥belelelbelow 그냥belelelelow 그냥belelelelow 그냥belelelow 그냥belelelow 그냥belelelow 그냥belelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelelel\n",
      "CPU times: user 24 s, sys: 103 ms, total: 24.1 s\n",
      "Wall time: 24.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## 인간 평가 방법\n",
    "from transformers import set_seed\n",
    "seed = 42\n",
    "\n",
    "set_seed(seed)\n",
    "\n",
    "index = 1666\n",
    "instruction = dataset['train'][index]['instruction']\n",
    "output = dataset['train'][index]['output']\n",
    "\n",
    "prompt = f\"Instruction:\\n{instruction}\\nOutput:\\n\"\n",
    "\n",
    "#원래 모델을 사용하여 수행한 것처럼 동일한 입력을 사용하지만 PEFT 모델을 사용하여 추론을 수행\n",
    "peft_model_res = gen(ft_model,prompt,350)\n",
    "peft_model_output = peft_model_res.split('Output:\\n')[1]\n",
    "print(peft_model_output)\n",
    "prefix, success, result = peft_model_output.partition('###')\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{prompt}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{output}\\n')\n",
    "print(dash_line)\n",
    "print(f'PEFT MODEL:\\n{prefix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7b5ba749-719d-4cf5-90f4-7e6947611849",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T13:06:26.553335Z",
     "iopub.status.busy": "2024-03-24T13:06:26.552600Z",
     "iopub.status.idle": "2024-03-24T13:06:49.306166Z",
     "shell.execute_reply": "2024-03-24T13:06:49.304054Z",
     "shell.execute_reply.started": "2024-03-24T13:06:26.553271Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elelowb 그냥 자랑:elowb 그냥 자랑' struction:\n",
      "클렌징폼과 비누의 차이가 무엇인가요?\n",
      "#### Instruction:\n",
      "클렌징폼과 비누의 차이가 무엇인가요?\n",
      "렌징폼과 비누의 차이가 무엇인가요?\n",
      "렌징폼과 비누의 차이가 무엇인가요?\n",
      "렌징폼과 비누의 차이가 무엇인가요?\n",
      "렌징폼과 비누의 차이가 무엇인가요?\n",
      "렌징폼과 비누의 차이가 무엇인가요?\n",
      "렌징폼과 비누의 차이가 무엇인가요?\n",
      "렌징폼과 비누의 차이가 무엇인가요?\n",
      "렌징폼과 비누의 차이가 무엇인가요?\n",
      "렌징폼과 비누의 차이가 무엇인가요?\n",
      "렌징폼과 비누의 차이가 무엇인가요?\n",
      "렌징폼과 비누의 차이가 무엇인가요?\n",
      "렌징폼과 비누의 차이가 무엇인가요?\n",
      "렌징폼과 비누의 차이가 무엇인가요?\n",
      "렌징폼과 비누의 차이가 무엇인가요?\n",
      "렌징폼과 비누의 차이가 무엇인가요?\n",
      "렌징폼과 비누의 차이가 무엇인가요?\n",
      "렌징폼과 비누의 차이가 무엇인가요?\n",
      "렌징폼과 비누의 차이가 무엇인가요?\n",
      "렌징폼과 비누의 차이가 무엇인가요?\n",
      "렌징폼과 비누의 차이가 무엇인가요?\n",
      "렌징폼\n",
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "Instruction:\n",
      "클렌징폼과 비누의 차이가 무엇인가요?\n",
      "얼굴 세정을 위해 클렌징폼과 비누를 모두 사용할 수 있지만, 클렌징폼과 비누의 차이가 궁금합니다.\n",
      "Output:\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "클렌징폼과 일반 비누의 가장 큰 차이는 세정력입니다. 일반비누보다는 클렌징폼의 세정력이 더 낫습니다. 하지만 일반 비누는 얼굴을 씻는 용도로 사용하면 안되며 반드시 클렌징폼으로 세정해주셔야 합니다.\n",
      "\n",
      "일반 비누는 PH 9~10인 알칼리성이기 때문에 우리의 피부 PH인 4.5~6.5와 차이가 매우 큽니다. 이것이 얼굴 씻을 때 피부에 필요한 피지막과 수분막까지 다 씻어내버리며, 반복되면 기미, 잡티 등의 문제를 유발합니다. \n",
      "\n",
      "반면, 클렌징폼은 약산성이며, 화학성분이 일반 비누보다 적게 들어가며 순하면서도 세정력이 좋은 것을 사용하는 것이 좋습니다. 필요한 성분이 들어간 클렌징폼으로 세정을 하시고, 변성알코올, 인공색소, 광물성 오일, 벤조페논 등이 들어간 클렌징폼은 피부에 자극적이며 인체에도 좋지 않기 때문에 피하는 것이 좋습니다.\n",
      "\n",
      "따라서, 일반비누를 사용하지 마시고, 좋은 성분이 들어간 클렌징폼으로 세정하세요.\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "PEFT MODEL:\n",
      "elelowb 그냥 자랑:elowb 그냥 자랑' struction:\n",
      "클렌징폼과 비누의 차이가 무엇인가요?\n",
      "\n",
      "CPU times: user 22.6 s, sys: 83.1 ms, total: 22.7 s\n",
      "Wall time: 22.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## 인간 평가 방법\n",
    "from transformers import set_seed\n",
    "seed = 42\n",
    "\n",
    "set_seed(seed)\n",
    "\n",
    "index = 21000\n",
    "instruction = dataset['train'][index]['instruction']\n",
    "output = dataset['train'][index]['output']\n",
    "\n",
    "prompt = f\"Instruction:\\n{instruction}\\nOutput:\\n\"\n",
    "\n",
    "#원래 모델을 사용하여 수행한 것처럼 동일한 입력을 사용하지만 PEFT 모델을 사용하여 추론을 수행\n",
    "peft_model_res = gen(ft_model,prompt,350)\n",
    "peft_model_output = peft_model_res.split('Output:\\n')[1]\n",
    "print(peft_model_output)\n",
    "prefix, success, result = peft_model_output.partition('###')\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{prompt}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{output}\\n')\n",
    "print(dash_line)\n",
    "print(f'PEFT MODEL:\\n{prefix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4fdcfd36-aecd-4951-9305-9bd71de0e02d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T13:07:31.577582Z",
     "iopub.status.busy": "2024-03-24T13:07:31.576407Z",
     "iopub.status.idle": "2024-03-24T13:07:56.125465Z",
     "shell.execute_reply": "2024-03-24T13:07:56.123107Z",
     "shell.execute_reply.started": "2024-03-24T13:07:31.577499Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "빛의 속도가 30만kmelb 그냥elb 그냥elrelb 그냥elrelb 그냥elrelb 그냥elrelb 그냥elrelb 그냥elrelb 그냥elrelb 그냥elrelb 그냥elrelrelb 그냥elrelrelrelb 그냥elrelrelrelb 그냥elrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelr\n",
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "Instruction:\n",
      "빛의 속도가 30만km인 것을 어떻게 알았을까요? 과학적 증명이나 실험에 의해 된 것이라면 근거를 알고 싶습니다.\n",
      "Output:\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "빛의 속도는 실험과 이론 양쪽으로부터 아주 정밀히 구할 수 있습니다. 1676년에는 덴마크의 뢰머라는 학자가 목성의 위성인 이오가 목성에 가려지는 현상을 이용하여 빛의 속도를 약 22만 km/s로 산출했습니다. 이후 브래들리의 광행차를 이용한 계산, 톱니바퀴를 이용한 피조의 방법, 그리고 19세기 후반에는 간섭계 등이 발견되어 정밀측정이 가능해졌습니다. 이론적으로는 파동방정식으로부터 계산되는데, 19세기 후반 영국의 Maxwell은 전기 자기 현상에 대한 4가지 기본 방정식을 발견하여 전자기파가 파동의 형태로 움직이는 파동방정식을 얻을 수 있었습니다. 이 식의 맨 끝 분모에 있는 v는 빛의 속도를 나타내며, 자장 대신 전장 E를 대입하여 전자기파의 속도를 계산할 수 있습니다. 이론적으로 구한 값은 실험을 통해 검증됩니다.\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "PEFT MODEL:\n",
      "빛의 속도가 30만kmelb 그냥elb 그냥elrelb 그냥elrelb 그냥elrelb 그냥elrelb 그냥elrelb 그냥elrelb 그냥elrelb 그냥elrelb 그냥elrelrelb 그냥elrelrelrelb 그냥elrelrelrelb 그냥elrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelrelr\n",
      "CPU times: user 24.2 s, sys: 141 ms, total: 24.4 s\n",
      "Wall time: 24.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## 인간 평가 방법\n",
    "from transformers import set_seed\n",
    "seed = 42\n",
    "\n",
    "set_seed(seed)\n",
    "\n",
    "index = 1111\n",
    "instruction = dataset['train'][index]['instruction']\n",
    "output = dataset['train'][index]['output']\n",
    "\n",
    "prompt = f\"Instruction:\\n{instruction}\\nOutput:\\n\"\n",
    "\n",
    "#원래 모델을 사용하여 수행한 것처럼 동일한 입력을 사용하지만 PEFT 모델을 사용하여 추론을 수행\n",
    "peft_model_res = gen(ft_model,prompt,350)\n",
    "peft_model_output = peft_model_res.split('Output:\\n')[1]\n",
    "print(peft_model_output)\n",
    "prefix, success, result = peft_model_output.partition('###')\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{prompt}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{output}\\n')\n",
    "print(dash_line)\n",
    "print(f'PEFT MODEL:\\n{prefix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "877359c4-bb70-471c-bc56-22f618da0418",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T13:07:56.134320Z",
     "iopub.status.busy": "2024-03-24T13:07:56.133314Z",
     "iopub.status.idle": "2024-03-24T13:08:20.849916Z",
     "shell.execute_reply": "2024-03-24T13:08:20.847587Z",
     "shell.execute_reply.started": "2024-03-24T13:07:56.134254Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elowruction' :\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를\n",
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "Instruction:\n",
      "서울 지하철 노선별 속도는 어떻게 되나요? 최고 속도와 평균 속도가 궁금합니다.\n",
      "Output:\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "서울 지하철 노선마다 다르지만, 각 구간의 최고 속도와 평균 속도가 정해져 있습니다. 1호선 경부선 구간은 소요산-인천 35.8km/h, 청량리-신창 46.6km/h, 용산-동인천급 42.9km/h, 용산-천안급 71.1km/h로 빠르게 운행합니다. 운행 최대 속도는 110km/h입니다. 종로3가에서부터 청량리 사이 구간에서는 최고 속도제한이 있어 속도가 느려져 33.7km/h입니다. 2~4호선은 평균 30~37km/h의 속도로 운행되고, 운행 최대 속도는 100km/h입니다. 5호선부터는 속도가 더 느려지며, 6~8호선은 평균 30~33km/h, 9호선은 완행 25.7km/h, 급행 44km/h로 운행되며, 운행 최대 속도는 90km/h입니다. 분당선은 완행 37km/h, 급행 41.3km/h로 운행되며, 일부 구간에서 100km/h로 운행됩니다. 각 노선의 구간별 속도는 다르니 이 점 참고해 주세요.\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "PEFT MODEL:\n",
      "elowruction' :\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를struction:\n",
      "서울 지하철 노선를\n",
      "CPU times: user 24.4 s, sys: 189 ms, total: 24.6 s\n",
      "Wall time: 24.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## 인간 평가 방법\n",
    "from transformers import set_seed\n",
    "seed = 42\n",
    "\n",
    "set_seed(seed)\n",
    "\n",
    "index = 577\n",
    "instruction = dataset['train'][index]['instruction']\n",
    "output = dataset['train'][index]['output']\n",
    "\n",
    "prompt = f\"Instruction:\\n{instruction}\\nOutput:\\n\"\n",
    "\n",
    "#원래 모델을 사용하여 수행한 것처럼 동일한 입력을 사용하지만 PEFT 모델을 사용하여 추론을 수행\n",
    "peft_model_res = gen(ft_model,prompt,350)\n",
    "peft_model_output = peft_model_res.split('Output:\\n')[1]\n",
    "print(peft_model_output)\n",
    "prefix, success, result = peft_model_output.partition('###')\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{prompt}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{output}\\n')\n",
    "print(dash_line)\n",
    "print(f'PEFT MODEL:\\n{prefix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6aa615de-0be6-445e-b693-1b88ba297d01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T13:08:58.086498Z",
     "iopub.status.busy": "2024-03-24T13:08:58.085731Z",
     "iopub.status.idle": "2024-03-24T13:09:23.413947Z",
     "shell.execute_reply": "2024-03-24T13:09:23.412341Z",
     "shell.execute_reply.started": "2024-03-24T13:08:58.086418Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "지구와의 비교점과 차이점에 대해 자세히 알려주세요.\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "Instruction:\n",
      "지구와 달의 비교점과 차이점에 대해 자세히 알려주세요.\n",
      "Output:\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "지구와 달은 우주에서 가까운 위치에 있음에도 불구하고, 그들 사이에는 많은 차이점이 존재합니다. 여러 측면에서 살펴봤을 때 지구와 달의 비교점과 차이점을 알려드리겠습니다.\n",
      "\n",
      " 공통점\n",
      "- 자전과 공전을 한다.\n",
      "- 둘 모두 동그란 구 모양을 가지고 있다.\n",
      "- 물이 존재한다.\n",
      "- 태양계에 속해 있다.\n",
      "\n",
      " 차이점\n",
      "- 지구는 대기가 있지만, 달은 없다.\n",
      "    - 이로 인해 지구는 일교차가 적고, 생물이 살 수 있지만, 달은 일교차가 크고 생물이 살 수 없다.\n",
      "- 지구는 행성이지만, 달은 위성이다.\n",
      "- 지구는 중력이 강하지만, 달은 중력이 약하다.\n",
      "- 지구는 구름이 많지만, 달은 구름이 없다.\n",
      "- 달은 크레이터가 존재하지만, 지구는 없다.\n",
      "- 지구는 자전 주기가 더 길고, 달은 공전 주기가 더 길다.\n",
      "\n",
      "이러한 지구와 달의 비교점과 차이점을 통해 두 행성이 어떤 측면에서 서로 다르고, 어떤 측면에서 유사한지를 이해할 수 있습니다.\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "PEFT MODEL:\n",
      "지구와의 비교점과 차이점에 대해 자세히 알려주세요.\n",
      "\n",
      "CPU times: user 25 s, sys: 245 ms, total: 25.2 s\n",
      "Wall time: 25.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## 인간 평가 방법\n",
    "from transformers import set_seed\n",
    "seed = 42\n",
    "\n",
    "set_seed(seed)\n",
    "\n",
    "index = 12343\n",
    "instruction = dataset['train'][index]['instruction']\n",
    "output = dataset['train'][index]['output']\n",
    "\n",
    "prompt = f\"Instruction:\\n{instruction}\\nOutput:\\n\"\n",
    "\n",
    "#원래 모델을 사용하여 수행한 것처럼 동일한 입력을 사용하지만 PEFT 모델을 사용하여 추론을 수행\n",
    "peft_model_res = gen(ft_model,prompt,350)\n",
    "peft_model_output = peft_model_res.split('Output:\\n')[1]\n",
    "print(peft_model_output)\n",
    "prefix, success, result = peft_model_output.partition('###')\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{prompt}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{output}\\n')\n",
    "print(dash_line)\n",
    "print(f'PEFT MODEL:\\n{prefix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cf9556a5-1bb9-40f6-9bab-f7c0dcb0e479",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T13:10:02.959021Z",
     "iopub.status.busy": "2024-03-24T13:10:02.957820Z",
     "iopub.status.idle": "2024-03-24T13:10:28.809268Z",
     "shell.execute_reply": "2024-03-24T13:10:28.807828Z",
     "shell.execute_reply.started": "2024-03-24T13:10:02.958938Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "극장elb 그냥 자랑elb 그냥 자랑elb 그냥 자랑elb 그냥 자랑elb 그냥 자랑elelb 그냥 자랑elb 그냥 자랑elb 그냥 자랑elelb 그냥 자랑elb 그냥 자랑elelb 그냥 자랑elb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelelb 그냥 자랑elelelb 그냥 자랑elelelb 그냥 자랑elelelb 그냥 자랑elelelb 그냥 자랑elelb 그냥 자랑elelelb 그냥 자랑elelelb 그냥 자랑elelelb 그냥 자랑elelelb 그냥 자랑elelelb 그냥 자랑elelelb 그냥 자랑elelelb 그냥 자랑elelelb 그냥 자랑elelelb 그냥 자랑elelelb 그냥 자랑elelelb 그냥 자랑elelelb 그냥 자랑elelelb 그냥 자랑elelelb 그냥 자랑elelelb 그냥\n",
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "Instruction:\n",
      "극장 의자 밑에는 왜 구멍이 있을까요?\n",
      "Output:\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "극장 의자의 아래부분에는 여러 개의 구멍이 있는데, 이는 소음을 줄여주는 역할을 합니다. 영화를 보는 사람이 의자에 앉으면 몸이나 옷이 소리를 흡수해 잡음을 없애지만, 사람이 앉지 않은 의자 아랫면은 여전히 소리를 반사시킵니다. 따라서 작은 구멍을 여러 개 뚫어서 소리가 구멍을 통해 들어가면 회절되어 퍼지고, 결국 의자 안으로 들어간 소리가 사라집니다. 그 외에도 극장 복도에 깔린 양탄자나, 극장 문을 가리는 커텐은 소음을 흡수하는 역할을 하며, 평면이 아닌 곡면으로 만들어진 벽면이나 천장은 소리의 난반사를 억제해서 메아리처럼 소리가 울리는 것을 막아줍니다.\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "PEFT MODEL:\n",
      "극장elb 그냥 자랑elb 그냥 자랑elb 그냥 자랑elb 그냥 자랑elb 그냥 자랑elelb 그냥 자랑elb 그냥 자랑elb 그냥 자랑elelb 그냥 자랑elb 그냥 자랑elelb 그냥 자랑elb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelb 그냥 자랑elelelb 그냥 자랑elelelb 그냥 자랑elelelb 그냥 자랑elelelb 그냥 자랑elelelb 그냥 자랑elelb 그냥 자랑elelelb 그냥 자랑elelelb 그냥 자랑elelelb 그냥 자랑elelelb 그냥 자랑elelelb 그냥 자랑elelelb 그냥 자랑elelelb 그냥 자랑elelelb 그냥 자랑elelelb 그냥 자랑elelelb 그냥 자랑elelelb 그냥 자랑elelelb 그냥 자랑elelelb 그냥 자랑elelelb 그냥 자랑elelelb 그냥\n",
      "CPU times: user 25.5 s, sys: 176 ms, total: 25.7 s\n",
      "Wall time: 25.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## 인간 평가 방법\n",
    "from transformers import set_seed\n",
    "seed = 42\n",
    "\n",
    "set_seed(seed)\n",
    "\n",
    "index = 11\n",
    "instruction = dataset['train'][index]['instruction']\n",
    "output = dataset['train'][index]['output']\n",
    "\n",
    "prompt = f\"Instruction:\\n{instruction}\\nOutput:\\n\"\n",
    "\n",
    "#원래 모델을 사용하여 수행한 것처럼 동일한 입력을 사용하지만 PEFT 모델을 사용하여 추론을 수행\n",
    "peft_model_res = gen(ft_model,prompt,350)\n",
    "peft_model_output = peft_model_res.split('Output:\\n')[1]\n",
    "print(peft_model_output)\n",
    "prefix, success, result = peft_model_output.partition('###')\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{prompt}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{output}\\n')\n",
    "print(dash_line)\n",
    "print(f'PEFT MODEL:\\n{prefix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a6b8429c-48e0-45de-b02d-d9d53a872af8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T13:11:03.735680Z",
     "iopub.status.busy": "2024-03-24T13:11:03.733478Z",
     "iopub.status.idle": "2024-03-24T13:11:29.849695Z",
     "shell.execute_reply": "2024-03-24T13:11:29.847864Z",
     "shell.execute_reply.started": "2024-03-24T13:11:03.735576Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한국에el 그냥 자랑ruction:Bel 그냥 자랑ruction' \"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'\n",
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "Instruction:\n",
      "한국에 대해 설명해줘nOutput:\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "꼽다와 꽂다는 많은 사람들이 헷갈려하는 단어입니다. 하지만 이 둘을 구분하는 방법이 있습니다. \"꼽다\"는 수나 날짜 등을 세려고 손가락을 헤아릴 때 사용하고, \"꽂다\"는 쓰러지지 않게 세우거나 고정할 때 사용합니다. 따라서 충전기를 콘센트에 연결할 때는 \"꽂다\"라는 표현을 사용하면 됩니다.\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "PEFT MODEL:\n",
      "한국에el 그냥 자랑ruction:Bel 그냥 자랑ruction' \"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'8:m\"'\n",
      "CPU times: user 25.9 s, sys: 89.7 ms, total: 26 s\n",
      "Wall time: 26.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## 인간 평가 방법\n",
    "from transformers import set_seed\n",
    "seed = 42\n",
    "\n",
    "set_seed(seed)\n",
    "\n",
    "index = 100\n",
    "instruction = dataset['train'][index]['instruction']\n",
    "output = dataset['train'][index]['output']\n",
    "\n",
    "prompt = f\"Instruction:\\n한국에 대해 설명해줘nOutput:\\n\"\n",
    "\n",
    "#원래 모델을 사용하여 수행한 것처럼 동일한 입력을 사용하지만 PEFT 모델을 사용하여 추론을 수행\n",
    "peft_model_res = gen(ft_model,prompt,350)\n",
    "peft_model_output = peft_model_res.split('Output:\\n')[1]\n",
    "print(peft_model_output)\n",
    "prefix, success, result = peft_model_output.partition('###')\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{prompt}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{output}\\n')\n",
    "print(dash_line)\n",
    "print(f'PEFT MODEL:\\n{prefix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e34191e7-37cb-40ce-af39-1a5b904b2002",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T13:12:02.474509Z",
     "iopub.status.busy": "2024-03-24T13:12:02.473341Z",
     "iopub.status.idle": "2024-03-24T13:12:28.153909Z",
     "shell.execute_reply": "2024-03-24T13:12:28.151630Z",
     "shell.execute_reply.started": "2024-03-24T13:12:02.474404Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "Instruction:\n",
      "한국을 빛낸 100명의 위인들nOutput:\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "꼽다와 꽂다는 많은 사람들이 헷갈려하는 단어입니다. 하지만 이 둘을 구분하는 방법이 있습니다. \"꼽다\"는 수나 날짜 등을 세려고 손가락을 헤아릴 때 사용하고, \"꽂다\"는 쓰러지지 않게 세우거나 고정할 때 사용합니다. 따라서 충전기를 콘센트에 연결할 때는 \"꽂다\"라는 표현을 사용하면 됩니다.\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "PEFT MODEL:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "한국을60struction:\n",
      "\n",
      "CPU times: user 25.4 s, sys: 179 ms, total: 25.6 s\n",
      "Wall time: 25.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## 인간 평가 방법\n",
    "from transformers import set_seed\n",
    "seed = 42\n",
    "\n",
    "set_seed(seed)\n",
    "\n",
    "index = 100\n",
    "instruction = dataset['train'][index]['instruction']\n",
    "output = dataset['train'][index]['output']\n",
    "\n",
    "prompt = f\"Instruction:\\n한국을 빛낸 100명의 위인들nOutput:\\n\"\n",
    "\n",
    "#원래 모델을 사용하여 수행한 것처럼 동일한 입력을 사용하지만 PEFT 모델을 사용하여 추론을 수행\n",
    "peft_model_res = gen(ft_model,prompt,350)\n",
    "peft_model_output = peft_model_res.split('Output:\\n')[1]\n",
    "print(peft_model_output)\n",
    "prefix, success, result = peft_model_output.partition('###')\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{prompt}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{output}\\n')\n",
    "print(dash_line)\n",
    "print(f'PEFT MODEL:\\n{prefix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e68ba4d6-396d-4e14-a198-d3521e7ac075",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T13:13:01.114914Z",
     "iopub.status.busy": "2024-03-24T13:13:01.114090Z",
     "iopub.status.idle": "2024-03-24T13:13:27.267382Z",
     "shell.execute_reply": "2024-03-24T13:13:27.266213Z",
     "shell.execute_reply.started": "2024-03-24T13:13:01.114837Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "Instruction:\n",
      "아름다운 학교nOutput:\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "꼽다와 꽂다는 많은 사람들이 헷갈려하는 단어입니다. 하지만 이 둘을 구분하는 방법이 있습니다. \"꼽다\"는 수나 날짜 등을 세려고 손가락을 헤아릴 때 사용하고, \"꽂다\"는 쓰러지지 않게 세우거나 고정할 때 사용합니다. 따라서 충전기를 콘센트에 연결할 때는 \"꽂다\"라는 표현을 사용하면 됩니다.\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "PEFT MODEL:\n",
      "belowruction 그냥bseostruction 그냥bseostructionelowruction 그냥bseostructionelowruction 그냥bseostructionelowruction 그냥bseostructionelowruction 그냥bseostructionelowruction 그냥bseostructionelowruction 그냥bseostructionelowruction 그냥bseostructionelowructionelowructionelowruction 그냥bseostructionelowruction 그냥bseostructionelowructionelowructionelowructionelowruction 그냥bseostructionelowructionelowructionelowructionelowructionelowructionelowructionelowructionelowructionelowructionelowructionelowructionelowructionelelowructionelowructionelelowructionelowructionelelowructionelowructionelelowructionelelowructionelelowructionelelowructionelelowructionelelowructionelelowructionelelowructionelelowructionelelowructionelelowructionelelowructionelelowructionelelowructionelelowructionelelelowructionelelelowructionelelelowructionelelowructionelelelowructionelelelowructionel\n",
      "CPU times: user 25.8 s, sys: 241 ms, total: 26 s\n",
      "Wall time: 26.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## 인간 평가 방법\n",
    "from transformers import set_seed\n",
    "seed = 42\n",
    "\n",
    "set_seed(seed)\n",
    "\n",
    "index = 100\n",
    "instruction = dataset['train'][index]['instruction']\n",
    "output = dataset['train'][index]['output']\n",
    "\n",
    "prompt = f\"Instruction:\\n아름다운 학교nOutput:\\n\"\n",
    "\n",
    "#원래 모델을 사용하여 수행한 것처럼 동일한 입력을 사용하지만 PEFT 모델을 사용하여 추론을 수행\n",
    "peft_model_res = gen(ft_model,prompt,350)\n",
    "peft_model_output = peft_model_res.split('Output:\\n')[1]\n",
    "# print(peft_model_output)\n",
    "prefix, success, result = peft_model_output.partition('###')\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{prompt}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{output}\\n')\n",
    "print(dash_line)\n",
    "print(f'PEFT MODEL:\\n{prefix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dc7ac492-a42f-4221-8b86-255ca9ff8a25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T13:14:04.451909Z",
     "iopub.status.busy": "2024-03-24T13:14:04.451033Z",
     "iopub.status.idle": "2024-03-24T13:14:25.630885Z",
     "shell.execute_reply": "2024-03-24T13:14:25.630012Z",
     "shell.execute_reply.started": "2024-03-24T13:14:04.451831Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전남 사찰에서 처음 본 꽃가루 모양의 벌레가 있어서 궁금합니다. 아에서 보듯이 꽃가루 모양의 벌레가 있었는데 처음 때 벌레임을 알 되었습니다. 이 벌레는 어떤 종류이며 외래종인가요?\n",
      "전남 사찰에서 처음 본 꽃가루 모양의 벌레가 있었는데 처음 때 벌레임을 알 되었습니다. 이 벌레는 어떤 종류이며 외래종인가요?\n",
      "전남 사찰에서 처음 본 꽃가루 모양의 벌레가 있었는데 처음 때 벌레임을 알 되었습니다. 이 벌레는 어떤 종류이며 외래종인가요?\n",
      "전남 사찰에서 처음 본 꽃가루 모양의 벌레가 있었는데 처음 때 벌레임을 알 되었습니다. 이 벌레는 어떤 종류이며 외래종인가요?\n",
      "전남 사찰에서 처음 본 꽃가루 모양의 벌레가 있었는데 처음 때 벌레임을 알 되었습니다. 이 벌레는 어떤 종류이며 외래종인가요?\n",
      "전남 사찰에서 처음 본 꽃가루 모양의 벌레가 있었는데 처음 때 벌레임을 알 되었습니다. 이 벌레는 어떤 종류이며 외래종인가요?\n",
      "전남 사찰에서 처음 본 꽃가루 모양의 벌레가 있었는데 처음 때 벌레임을 알 되었습니다. 이 벌레는 어떤 종류이며 외래종인가요\n",
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "Instruction:\n",
      "전남 사찰에서 발견한 꽃가루 모양의 벌레는 무엇인가요? 외래종인가요?\n",
      "전남 사찰에서 처음 본 꽃가루 모양의 벌레가 있어서 궁금합니다. 사진에서 보듯이 꽃가루 같은 외형을 가지고 있었는데 움직일 때 벌레임을 알게 되었습니다. 이 벌레는 어떤 종류이며 외래종인가요?nOutput:\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "사진에서 보이는 곤충은 매미목>선녀벌레과>갈색날개매미충(학명:Pochazia sp.) 입니다. 이 벌레는 최근에 우리나라에 급속도로 번식하며 외래곤충으로 분류됩니다. 약충은 밝은 노란색 또는 흰색을 띠며, 몸의 끝부분에 돌기 모양의 털에 밀랍을 분비하여 꽃처럼 보이는 형태를 띱니다. 이러한 외형은 천적들의 시각적인 효과를 유도하여 무심결에 지나치도록 유도하는 것이며, 6~8월 사이에 갈색날매미충의 성충이나 약충은 식물의 즙액을 빨아먹으며 그을음병을 유발해 해충으로 불리게 됩니다.\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "PEFT MODEL:\n",
      "전남 사찰에서 처음 본 꽃가루 모양의 벌레가 있어서 궁금합니다. 아에서 보듯이 꽃가루 모양의 벌레가 있었는데 처음 때 벌레임을 알 되었습니다. 이 벌레는 어떤 종류이며 외래종인가요?\n",
      "전남 사찰에서 처음 본 꽃가루 모양의 벌레가 있었는데 처음 때 벌레임을 알 되었습니다. 이 벌레는 어떤 종류이며 외래종인가요?\n",
      "전남 사찰에서 처음 본 꽃가루 모양의 벌레가 있었는데 처음 때 벌레임을 알 되었습니다. 이 벌레는 어떤 종류이며 외래종인가요?\n",
      "전남 사찰에서 처음 본 꽃가루 모양의 벌레가 있었는데 처음 때 벌레임을 알 되었습니다. 이 벌레는 어떤 종류이며 외래종인가요?\n",
      "전남 사찰에서 처음 본 꽃가루 모양의 벌레가 있었는데 처음 때 벌레임을 알 되었습니다. 이 벌레는 어떤 종류이며 외래종인가요?\n",
      "전남 사찰에서 처음 본 꽃가루 모양의 벌레가 있었는데 처음 때 벌레임을 알 되었습니다. 이 벌레는 어떤 종류이며 외래종인가요?\n",
      "전남 사찰에서 처음 본 꽃가루 모양의 벌레가 있었는데 처음 때 벌레임을 알 되었습니다. 이 벌레는 어떤 종류이며 외래종인가요\n",
      "CPU times: user 20.9 s, sys: 118 ms, total: 21.1 s\n",
      "Wall time: 21.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## 인간 평가 방법\n",
    "from transformers import set_seed\n",
    "seed = 42\n",
    "\n",
    "set_seed(seed)\n",
    "\n",
    "index = 101\n",
    "instruction = dataset['train'][index]['instruction']\n",
    "output = dataset['train'][index]['output']\n",
    "\n",
    "prompt = f\"Instruction:\\n{instruction}nOutput:\\n\"\n",
    "\n",
    "#원래 모델을 사용하여 수행한 것처럼 동일한 입력을 사용하지만 PEFT 모델을 사용하여 추론을 수행\n",
    "peft_model_res = gen(ft_model,prompt,350)\n",
    "peft_model_output = peft_model_res.split('Output:\\n')[1]\n",
    "print(peft_model_output)\n",
    "prefix, success, result = peft_model_output.partition('###')\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{prompt}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{output}\\n')\n",
    "print(dash_line)\n",
    "print(f'PEFT MODEL:\\n{prefix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "91d8012c-639f-4de8-a03a-e83fbffc0137",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T13:19:58.142034Z",
     "iopub.status.busy": "2024-03-24T13:19:58.140920Z",
     "iopub.status.idle": "2024-03-24T13:20:18.035992Z",
     "shell.execute_reply": "2024-03-24T13:20:18.033437Z",
     "shell.execute_reply.started": "2024-03-24T13:19:58.141948Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "Instruction: Answer the questions below\n",
      "전남 사찰에서 발견한 꽃가루 모양의 벌레는 무엇인가요? 외래종인가요?\n",
      "전남 사찰에서 처음 본 꽃가루 모양의 벌레가 있어서 궁금합니다. 사진에서 보듯이 꽃가루 같은 외형을 가지고 있었는데 움직일 때 벌레임을 알게 되었습니다. 이 벌레는 어떤 종류이며 외래종인가요?\n",
      "Output:\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "사진에서 보이는 곤충은 매미목>선녀벌레과>갈색날개매미충(학명:Pochazia sp.) 입니다. 이 벌레는 최근에 우리나라에 급속도로 번식하며 외래곤충으로 분류됩니다. 약충은 밝은 노란색 또는 흰색을 띠며, 몸의 끝부분에 돌기 모양의 털에 밀랍을 분비하여 꽃처럼 보이는 형태를 띱니다. 이러한 외형은 천적들의 시각적인 효과를 유도하여 무심결에 지나치도록 유도하는 것이며, 6~8월 사이에 갈색날매미충의 성충이나 약충은 식물의 즙액을 빨아먹으며 그을음병을 유발해 해충으로 불리게 됩니다.\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "PEFT MODEL:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "CPU times: user 19.5 s, sys: 250 ms, total: 19.8 s\n",
      "Wall time: 19.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## 인간 평가 방법\n",
    "from transformers import set_seed\n",
    "seed = 42\n",
    "\n",
    "set_seed(seed)\n",
    "\n",
    "index = 101\n",
    "instruction = dataset['train'][index]['instruction']\n",
    "output = dataset['train'][index]['output']\n",
    "\n",
    "prompt = f\"Instruction: Answer the questions below\\n{instruction}\\nOutput:\\n\"\n",
    "\n",
    "#원래 모델을 사용하여 수행한 것처럼 동일한 입력을 사용하지만 PEFT 모델을 사용하여 추론을 수행\n",
    "peft_model_res = gen(ft_model,prompt,350)\n",
    "peft_model_output = peft_model_res.split('Output:\\n')[1]\n",
    "print(peft_model_output)\n",
    "prefix, success, result = peft_model_output.partition('###')\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{prompt}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{output}\\n')\n",
    "print(dash_line)\n",
    "print(f'PEFT MODEL:\\n{prefix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c863438e-75db-44ae-b794-46a2df0570d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T13:25:26.438142Z",
     "iopub.status.busy": "2024-03-24T13:25:26.437298Z",
     "iopub.status.idle": "2024-03-24T13:25:44.726536Z",
     "shell.execute_reply": "2024-03-24T13:25:44.725612Z",
     "shell.execute_reply.started": "2024-03-24T13:25:26.438066Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "Instruct: Answer the questions below\n",
      "보이차를 어떻게 마셔야 할까요? 처음에 첫물을 버려야 하나요? 보이차의 독성이 있을까요? 또 다른 음용법은 어떤 것이 있나요? \n",
      "어머니께서 유명다과점에서 구매한 보이차를 마셔보려고 하지만 어떻게 마셔야 할지 모르겠습니다. 처음 우린 물은 버려야 하는지, 보이차에 독성이 있는지 궁금합니다. 또한, 보이차를 마시는 다른 방법에 대해서도 알려주세요.\n",
      "Output:\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "보이차는 제조 과정에서 독성을 제거하기 때문에 보통 첫물을 버리지 않아도 괜찮습니다. 하지만, 보이차의 첫물은 독성성분이 조금 높은 편이므로 차를 더욱 깨끗하게 즐기기 위해서는 버리는 것이 좋습니다. 보이차는 여러 가지 방법으로 음용할 수 있습니다. 일반적으로는 물이 팔팔 끓을 때 보이차를 넣어서 5분 정도 우려냅니다. 또 다른 방법은 다구를 이용하는 것인데, 보이차를 다구에 넣고 끓는 물을 부어서 20~30번 가량 우려내면 됩니다. 그리고 잘 우린 보이차는 거름막을 이용하여 걸러서 유리 주전자에 담아 식기 전에 마시면 됩니다.\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "PEFT MODEL:\n",
      "어머니께서 유명다과점에서 구매한 보이차를적��셔야 될 있 처음에 첫물을 버려야 하나요? 보이차를적��셔야 될 있 처음에 첫물을 버려야 하나요? 보이차를적��셔야 될 있 처음에 첫물을 버려야 하나요? 보이차를적��셔야 될 있 처음에 첫물을 버려야 하나요? 보이차를적��셔야 될 있 처음에 첫물을 버려야 하나요? 보이차를적��셔야 될 있 처음에 첫물을 버려야 하나요? 보이차를적��셔야 될 있 처음에 첫물을 버려야 하나요? 보이차를적��셔야 될 있 처음에 첫물을 버려야 하나요? 보이차를적��셔야 될 있 처음에 첫물을 버려야 하나요? 보이차를적��셔야 될 있 처음에 첫물을 버려야 하나요? 보이차를적��셔야 될 있 처음에 첫물을 버려야 하나요? 보이차를적��셔야 될 있 처음에 첫물을 버려야 하나요? 보이차를적��셔야 될 있 처음에 첫물을 버려야 하나\n",
      "CPU times: user 18.1 s, sys: 96.2 ms, total: 18.2 s\n",
      "Wall time: 18.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## 인간 평가 방법\n",
    "from transformers import set_seed\n",
    "seed = 42\n",
    "\n",
    "set_seed(seed)\n",
    "\n",
    "index = 999\n",
    "instruction = dataset['train'][index]['instruction']\n",
    "output = dataset['train'][index]['output']\n",
    "\n",
    "prompt = f\"Instruct: Answer the questions below\\n{instruction}\\nOutput:\\n\"\n",
    "\n",
    "#원래 모델을 사용하여 수행한 것처럼 동일한 입력을 사용하지만 PEFT 모델을 사용하여 추론을 수행\n",
    "peft_model_res = gen(ft_model,prompt,350)\n",
    "peft_model_output = peft_model_res.split('Output:\\n')[1]\n",
    "prefix, success, result = peft_model_output.partition('###')\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{prompt}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{output}\\n')\n",
    "print(dash_line)\n",
    "print(f'PEFT MODEL:\\n{prefix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "18e449d1-7536-4500-becf-972d15ca84d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T13:26:14.095391Z",
     "iopub.status.busy": "2024-03-24T13:26:14.093325Z",
     "iopub.status.idle": "2024-03-24T13:26:32.423724Z",
     "shell.execute_reply": "2024-03-24T13:26:32.422756Z",
     "shell.execute_reply.started": "2024-03-24T13:26:14.095305Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "Instruct: Answer the questions below\n",
      "보이차를 어떻게 마셔야 할까요? 처음에 첫물을 버려야 하나요? 보이차의 독성이 있을까요? 또 다른 음용법은 어떤 것이 있나요? \n",
      "어머니께서 유명다과점에서 구매한 보이차를 마셔보려고 하지만 어떻게 마셔야 할지 모르겠습니다. 처음 우린 물은 버려야 하는지, 보이차에 독성이 있는지 궁금합니다. 또한, 보이차를 마시는 다른 방법에 대해서도 알려주세요.\n",
      "Output:\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "보이차는 제조 과정에서 독성을 제거하기 때문에 보통 첫물을 버리지 않아도 괜찮습니다. 하지만, 보이차의 첫물은 독성성분이 조금 높은 편이므로 차를 더욱 깨끗하게 즐기기 위해서는 버리는 것이 좋습니다. 보이차는 여러 가지 방법으로 음용할 수 있습니다. 일반적으로는 물이 팔팔 끓을 때 보이차를 넣어서 5분 정도 우려냅니다. 또 다른 방법은 다구를 이용하는 것인데, 보이차를 다구에 넣고 끓는 물을 부어서 20~30번 가량 우려내면 됩니다. 그리고 잘 우린 보이차는 거름막을 이용하여 걸러서 유리 주전자에 담아 식기 전에 마시면 됩니다.\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "PEFT MODEL:\n",
      "어머니께서 유명다과점에서 구매한 보이차를적��셔야 될 있 처음에 첫물을 버려야 하나요? 보이차를적��셔야 될 있 처음에 첫물을 버려야 하나요? 보이차를적��셔야 될 있 처음에 첫물을 버려야 하나요? 보이차를적��셔야 될 있 처음에 첫물을 버려야 하나요? 보이차를적��셔야 될 있 처음에 첫물을 버려야 하나요? 보이차를적��셔야 될 있 처음에 첫물을 버려야 하나요? 보이차를적��셔야 될 있 처음에 첫물을 버려야 하나요? 보이차를적��셔야 될 있 처음에 첫물을 버려야 하나요? 보이차를적��셔야 될 있 처음에 첫물을 버려야 하나요? 보이차를적��셔야 될 있 처음에 첫물을 버려야 하나요? 보이차를적��셔야 될 있 처음에 첫물을 버려야 하나요? 보이차를적��셔야 될 있 처음에 첫물을 버려야 하나요? 보이차를적��셔야 될 있 처음에 첫물을 버려야 하나\n",
      "CPU times: user 18.1 s, sys: 86.2 ms, total: 18.2 s\n",
      "Wall time: 18.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## 인간 평가 방법\n",
    "from transformers import set_seed\n",
    "seed = 42\n",
    "\n",
    "set_seed(seed)\n",
    "\n",
    "index = 999\n",
    "instruction = dataset['train'][index]['instruction']\n",
    "output = dataset['train'][index]['output']\n",
    "\n",
    "prompt = f\"Instruct: Answer the questions below\\n{instruction}\\nOutput:\\n\"\n",
    "\n",
    "#원래 모델을 사용하여 수행한 것처럼 동일한 입력을 사용하지만 PEFT 모델을 사용하여 추론을 수행\n",
    "peft_model_res = gen(ft_model,prompt,350)\n",
    "peft_model_output = peft_model_res.split('Output:\\n')[1]\n",
    "prefix, success, result = peft_model_output.partition('###')\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{prompt}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{output}\\n')\n",
    "print(dash_line)\n",
    "print(f'PEFT MODEL:\\n{prefix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7f396ef8-02c4-448e-afeb-f18519edbd82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T13:26:32.425833Z",
     "iopub.status.busy": "2024-03-24T13:26:32.425407Z",
     "iopub.status.idle": "2024-03-24T13:26:53.379057Z",
     "shell.execute_reply": "2024-03-24T13:26:53.378483Z",
     "shell.execute_reply.started": "2024-03-24T13:26:32.425803Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "Instruct: Answer the questions below\n",
      "포석정에서 술잔을 띄울 때 물 결의 흐름에 따라 거칠면 쏟아지지 않을까요? \n",
      "저는 포석정에서 술잔을 띄울 때 술잔이 왜 안 넘어지는지 궁금합니다. 파인 구멍으로 물이 흐르는데 흐름이 세질수록 술잔이 흔들리는데 쏟아질까 걱정입니다.\n",
      "Output:\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "포석정의 수로는 와류 현상을 이용하여 술잔이 물결에 따라 쏟아지지 않도록 설계되어 있습니다. 물속도가 느리기 때문에 물결이 세지 않으며, 수로 굴곡에 의해 물이 일정한 장소에서 회돌이현상이 발생하여 술잔이 일정한 위치에서 머무르게 됩니다. 포석정의 수로 길이가 짧아 2-3분 걸리므로, 술잔을 띄운 후 셧구를 지을 시간으로 이용하던 것입니다. 이러한 과학 기술을 활용해 선조들은 유래 모양을 따른 수로를 만들고, 높이 약 20cm, 폭이 15cm 정도 되는 측벽을 63개의 석재로 안정적인 구조를 만들어 술잔을 안전하게 띄웠습니다. 우주선과 미사일 탱크 등 실무 공학적인 면에서는 회돌이 현상을 방지하나, 선조들은 와류 현상을 실용적으로 활용한 업적입니다.\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "PEFT MODEL:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "Out:\n",
      "O\n",
      "CPU times: user 20.8 s, sys: 76.3 ms, total: 20.8 s\n",
      "Wall time: 20.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## 인간 평가 방법\n",
    "from transformers import set_seed\n",
    "seed = 42\n",
    "\n",
    "set_seed(seed)\n",
    "\n",
    "index = 98\n",
    "instruction = dataset['train'][index]['instruction']\n",
    "output = dataset['train'][index]['output']\n",
    "\n",
    "prompt = f\"Instruct: Answer the questions below\\n{instruction}\\nOutput:\\n\"\n",
    "\n",
    "#원래 모델을 사용하여 수행한 것처럼 동일한 입력을 사용하지만 PEFT 모델을 사용하여 추론을 수행\n",
    "peft_model_res = gen(ft_model,prompt,350)\n",
    "peft_model_output = peft_model_res.split('Output:\\n')[1]\n",
    "prefix, success, result = peft_model_output.partition('###')\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{prompt}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{output}\\n')\n",
    "print(dash_line)\n",
    "print(f'PEFT MODEL:\\n{prefix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1a1785fd-d350-4f00-9bd0-1d18d3cca404",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T13:30:20.046042Z",
     "iopub.status.busy": "2024-03-24T13:30:20.045269Z",
     "iopub.status.idle": "2024-03-24T13:30:36.493287Z",
     "shell.execute_reply": "2024-03-24T13:30:36.491780Z",
     "shell.execute_reply.started": "2024-03-24T13:30:20.045975Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "Instruct: Answer the questions below\n",
      "\n",
      "포석정에서 술잔을 띄울 때 물 결의 흐름에 따라 거칠면 쏟아지지 않을까요? \n",
      "저는 포석정에서 술잔을 띄울 때 술잔이 왜 안 넘어지는지 궁금합니다. 파인 구멍으로 물이 흐르는데 흐름이 세질수록 술잔이 흔들리는데 쏟아질까 걱정입니다.\n",
      "Output:\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "포석정의 수로는 와류 현상을 이용하여 술잔이 물결에 따라 쏟아지지 않도록 설계되어 있습니다. 물속도가 느리기 때문에 물결이 세지 않으며, 수로 굴곡에 의해 물이 일정한 장소에서 회돌이현상이 발생하여 술잔이 일정한 위치에서 머무르게 됩니다. 포석정의 수로 길이가 짧아 2-3분 걸리므로, 술잔을 띄운 후 셧구를 지을 시간으로 이용하던 것입니다. 이러한 과학 기술을 활용해 선조들은 유래 모양을 따른 수로를 만들고, 높이 약 20cm, 폭이 15cm 정도 되는 측벽을 63개의 석재로 안정적인 구조를 만들어 술잔을 안전하게 띄웠습니다. 우주선과 미사일 탱크 등 실무 공학적인 면에서는 회돌이 현상을 방지하나, 선조들은 와류 현상을 실용적으로 활용한 업적입니다.\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "PEFT MODEL:\n",
      "\n",
      "포석정에서 술잔을 띄울 때 술잔이 왜 안 넘어지는지 궁금합니다.\n",
      "\n",
      "포석정에서 술잔을 띄울 때 술잔이 왜 안 넘어지는지 궁금합니다.\n",
      "\n",
      "포석정에서 술잔을 띄울 때 술잔이 왜 안 넘어지는지 궁금합니다.\n",
      "\n",
      "포석정에서 술잔을 띄울 때 술잔이 왜 안 넘어지는지 궁금합니다.\n",
      "\n",
      "포석정에서 술잔을 띄울 때 술잔이 왜 안 넘어지는지 궁금합니다.\n",
      "\n",
      "포석정에서 술잔을 띄울 때 술잔이 왜 안 넘어지는지 궁금합니다.\n",
      "\n",
      "포석정에서 술잔을 띄울 때 술잔이 왜 안 넘어지는지 궁금합니다.\n",
      "\n",
      "포석정에서 술잔을 띄울 때 술잔이 왜 안 넘어지는지 궁금합니다.\n",
      "\n",
      "포석정에서 술잔을 띄울 때 술잔이 왜 안 넘어지는지 궁금합니다.\n",
      "\n",
      "포석정에서 술잔을 띄울 때 술잔이 왜 안 넘어지는지 궁금합니다.\n",
      "\n",
      "포석정에서 술잔을\n",
      "CPU times: user 16.3 s, sys: 93.7 ms, total: 16.4 s\n",
      "Wall time: 16.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## 인간 평가 방법\n",
    "from transformers import set_seed\n",
    "seed = 42\n",
    "\n",
    "set_seed(seed)\n",
    "\n",
    "index = 98\n",
    "instruction = dataset['train'][index]['instruction']\n",
    "output = dataset['train'][index]['output']\n",
    "\n",
    "prompt = f\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\nInstruct: Answer the questions below\\n\\n{instruction}\\nOutput:\\n\\n\"\n",
    "\n",
    "#원래 모델을 사용하여 수행한 것처럼 동일한 입력을 사용하지만 PEFT 모델을 사용하여 추론을 수행\n",
    "peft_model_res = gen(ft_model,prompt,350)\n",
    "peft_model_output = peft_model_res.split('Output:\\n')[1]\n",
    "prefix, success, result = peft_model_output.partition('###')\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{prompt}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{output}\\n')\n",
    "print(dash_line)\n",
    "print(f'PEFT MODEL:\\n{prefix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5b774dc3-fe52-47f5-bddc-514f66abe339",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T13:32:08.008179Z",
     "iopub.status.busy": "2024-03-24T13:32:08.006742Z",
     "iopub.status.idle": "2024-03-24T13:32:28.756715Z",
     "shell.execute_reply": "2024-03-24T13:32:28.754355Z",
     "shell.execute_reply.started": "2024-03-24T13:32:08.008071Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "Instruct: Answer the questions below\n",
      "\n",
      "포석정에서 술잔을 띄울 때 물 결의 흐름에 따라 거칠면 쏟아지지 않을까요? \n",
      "저는 포석정에서 술잔을 띄울 때 술잔이 왜 안 넘어지는지 궁금합니다. 파인 구멍으로 물이 흐르는데 흐름이 세질수록 술잔이 흔들리는데 쏟아질까 걱정입니다.\n",
      "\n",
      "Output:\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "포석정의 수로는 와류 현상을 이용하여 술잔이 물결에 따라 쏟아지지 않도록 설계되어 있습니다. 물속도가 느리기 때문에 물결이 세지 않으며, 수로 굴곡에 의해 물이 일정한 장소에서 회돌이현상이 발생하여 술잔이 일정한 위치에서 머무르게 됩니다. 포석정의 수로 길이가 짧아 2-3분 걸리므로, 술잔을 띄운 후 셧구를 지을 시간으로 이용하던 것입니다. 이러한 과학 기술을 활용해 선조들은 유래 모양을 따른 수로를 만들고, 높이 약 20cm, 폭이 15cm 정도 되는 측벽을 63개의 석재로 안정적인 구조를 만들어 술잔을 안전하게 띄웠습니다. 우주선과 미사일 탱크 등 실무 공학적인 면에서는 회돌이 현상을 방지하나, 선조들은 와류 현상을 실용적으로 활용한 업적입니다.\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "PEFT MODEL:\n",
      "포석정에서 술잔을 띄울 때 물 결의 어려웠에 따라 거칠면 쏟아지지 않을까요?\n",
      "\n",
      "포석정에서 술잔을 띄울 때 물 결의 어려웠에 따라 거칠면 쏟아지지 않을까요?\n",
      "\n",
      "포석정에서 술잔을 띄울 때 물 결의 어려웠에 따라 거칠면 쏟아지지 않을까요?\n",
      "\n",
      "포석정에서 술잔을 띄울 때 물 결의 어려웠에 따라 거칠면 쏟아지지 않을까요?\n",
      "\n",
      "포석정에서 술잔을 띄울 때 물 결의 어려웠에 따라 거칠면 쏟아지지 않을까요?\n",
      "\n",
      "포석정에서 술잔을 띄울 때 물 결의 어려웠에 따라 거칠면 쏟아지지 않을까요?\n",
      "\n",
      "포석정에서 술잔을 띄울 때 물 결의 어려웠에 따라 거칠면 쏟아지지 않을까요?\n",
      "\n",
      "포석정에서 술잔을 띄울 때 물 결의 어려웠에 따라 거칠면 쏟아지지 않을까요?\n",
      "\n",
      "포석정에서 술잔을 띄울 때 물 결의 어려웠에 따라 거칠면 쏟아지지 않을까요?\n",
      "\n",
      "포석정에서 술잔을 띄울 때 물 결의 어려웠에 따라 거칠면 쏟아지지 않을까요?\n",
      "\n",
      "포석정에서 술잔을 띄울 때 물 결의 어려웠에 따라 거칠면 쏟아지지 않을까요?\n",
      "\n",
      "포석정에서 술잔을\n",
      "CPU times: user 20.5 s, sys: 139 ms, total: 20.6 s\n",
      "Wall time: 20.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## 인간 평가 방법\n",
    "from transformers import set_seed\n",
    "seed = 42\n",
    "\n",
    "set_seed(seed)\n",
    "\n",
    "index = 98\n",
    "instruction = dataset['train'][index]['instruction']\n",
    "output = dataset['train'][index]['output']\n",
    "\n",
    "prompt = f\"Instruct: Answer the questions below\\n\\n{instruction}\\n\\nOutput:\\n\"\n",
    "\n",
    "#원래 모델을 사용하여 수행한 것처럼 동일한 입력을 사용하지만 PEFT 모델을 사용하여 추론을 수행\n",
    "peft_model_res = gen(ft_model,prompt,350)\n",
    "peft_model_output = peft_model_res.split('Output:\\n')[1]\n",
    "prefix, success, result = peft_model_output.partition('###')\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{prompt}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{output}\\n')\n",
    "print(dash_line)\n",
    "print(f'PEFT MODEL:\\n{prefix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6bc345a2-25b1-4ec5-aac7-e52211385f1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T13:35:26.728648Z",
     "iopub.status.busy": "2024-03-24T13:35:26.727836Z",
     "iopub.status.idle": "2024-03-24T13:35:51.117854Z",
     "shell.execute_reply": "2024-03-24T13:35:51.115735Z",
     "shell.execute_reply.started": "2024-03-24T13:35:26.728575Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "Instruct: Answer the questions below\n",
      "\n",
      "미국에도 동시지방선거가 있나요?\n",
      "\n",
      "Output:\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "미국은 일년 내내 다양한 선거를 진행합니다. 대통령과 주지사, 시장 등 일부 고위직은 4년 주기로 교체되며, 연방 하원의회의 경우 2년마다 1/3가 변경됩니다. 또한 교육위원, 선거관리위원, 시의회 의원, 지역 법원판사 등 많은 지방공직자들이 선출됩니다. 토지평가 업무를 담당하는 직책과 세금징수 업무를 담당하는 공무원들도 선출직입니다. 미국에서는 도시의 크기나 구성원 수에 따라 다양한 유형의 선거가 실시되며, 그만큼 많은 수의 선거인들이 길거리에 등록되어 있어 일년 내내 투표를 할 수 있습니다. \n",
      "\n",
      "단순한 동시지방선거와는 달리, 미국에서는 다양한 종류의 지방선거가 있으며, 한 해 내내 선거가 이루어집니다. 따라서 미국에서는 일반적인 '동시지방선거'는 없다고 볼 수 있습니다.\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "PEFT MODEL:\n",
      "#: Anser the questions below\n",
      "\n",
      "미국에도 동시지방선거가 있나요?\n",
      "\n",
      "\n",
      "CPU times: user 24.2 s, sys: 132 ms, total: 24.3 s\n",
      "Wall time: 24.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## 인간 평가 방법\n",
    "from transformers import set_seed\n",
    "seed = 42\n",
    "\n",
    "set_seed(seed)\n",
    "\n",
    "index = 121\n",
    "instruction = dataset['train'][index]['instruction']\n",
    "output = dataset['train'][index]['output']\n",
    "\n",
    "prompt = f\"Instruct: Answer the questions below\\n\\n{instruction}\\n\\nOutput:\\n\"\n",
    "\n",
    "#원래 모델을 사용하여 수행한 것처럼 동일한 입력을 사용하지만 PEFT 모델을 사용하여 추론을 수행\n",
    "peft_model_res = gen(ft_model,prompt,350)\n",
    "peft_model_output = peft_model_res.split('Output:\\n')[1]\n",
    "prefix, success, result = peft_model_output.partition('###')\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{prompt}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{output}\\n')\n",
    "print(dash_line)\n",
    "print(f'PEFT MODEL:\\n{prefix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e9127b4a-a967-433e-b75d-31040ac93c6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T13:37:01.004161Z",
     "iopub.status.busy": "2024-03-24T13:37:01.003249Z",
     "iopub.status.idle": "2024-03-24T13:37:21.271514Z",
     "shell.execute_reply": "2024-03-24T13:37:21.267775Z",
     "shell.execute_reply.started": "2024-03-24T13:37:01.004080Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "Instruct: Answer the questions below\n",
      "\n",
      "미국에도 동시지방선거가 있나요?\n",
      "\n",
      "Output:\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "미국은 일년 내내 다양한 선거를 진행합니다. 대통령과 주지사, 시장 등 일부 고위직은 4년 주기로 교체되며, 연방 하원의회의 경우 2년마다 1/3가 변경됩니다. 또한 교육위원, 선거관리위원, 시의회 의원, 지역 법원판사 등 많은 지방공직자들이 선출됩니다. 토지평가 업무를 담당하는 직책과 세금징수 업무를 담당하는 공무원들도 선출직입니다. 미국에서는 도시의 크기나 구성원 수에 따라 다양한 유형의 선거가 실시되며, 그만큼 많은 수의 선거인들이 길거리에 등록되어 있어 일년 내내 투표를 할 수 있습니다. \n",
      "\n",
      "단순한 동시지방선거와는 달리, 미국에서는 다양한 종류의 지방선거가 있으며, 한 해 내내 선거가 이루어집니다. 따라서 미국에서는 일반적인 '동시지방선거'는 없다고 볼 수 있습니다.\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "PEFT MODEL:\n",
      "미국에도 동시지방선거가 있나요?\n",
      "\n",
      "미국에도 동시지방선거가 있나요?\n",
      "\n",
      "미국에도 동시지방선거가 있나요?\n",
      "\n",
      "미국에도 동시지방선거가 있나요?\n",
      "\n",
      "미국에도 동시지방선거가 있나요?\n",
      "\n",
      "미국에도 동시지방선거가 있나요?\n",
      "\n",
      "미국에도 동시지방선거가 있나요?\n",
      "\n",
      "미국에도 동시지방선거가 있나요?\n",
      "\n",
      "미국에도 동시지방선거가 있나요?\n",
      "\n",
      "미국에도 동시지방선거가 있나요?\n",
      "\n",
      "미국에도 동시지방선거가 있나요?\n",
      "\n",
      "미국에도 동시지방선거가 있나요?\n",
      "\n",
      "미국에도 동시지방선거가 있나요?\n",
      "\n",
      "미국에도 동시지방선거가 있나요?\n",
      "\n",
      "미국에도 동시지방선거가 있나요?\n",
      "\n",
      "미국에도 동시지방선거가 있나요?\n",
      "\n",
      "미국에도 동시지방선거가 있나요?\n",
      "\n",
      "미국에도 동시지방선거가 있나요?\n",
      "\n",
      "미국에도 동시지방선거가 있나요?\n",
      "\n",
      "미국에도 동시지방선거가 있나요?\n",
      "\n",
      "미국에도 동시지방선거가 있나요?\n",
      "\n",
      "미국에도 동시지방선거가 있나요?\n",
      "\n",
      "미국에도 동시지방선거가 있나요?\n",
      "\n",
      "미국에도 동시지방선거가\n",
      "CPU times: user 20.1 s, sys: 99.6 ms, total: 20.2 s\n",
      "Wall time: 20.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## 인간 평가 방법\n",
    "from transformers import set_seed\n",
    "seed = 42\n",
    "\n",
    "set_seed(seed)\n",
    "\n",
    "index = 121\n",
    "instruction = dataset['train'][index]['instruction']\n",
    "output = dataset['train'][index]['output']\n",
    "\n",
    "prompt = f\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\nInstruct: Answer the questions below\\n\\n{instruction}\\n\\nOutput:\\n\"\n",
    "\n",
    "#원래 모델을 사용하여 수행한 것처럼 동일한 입력을 사용하지만 PEFT 모델을 사용하여 추론을 수행\n",
    "peft_model_res = gen(ft_model,prompt,350)\n",
    "peft_model_output = peft_model_res.split('Output:\\n')[1]\n",
    "prefix, success, result = peft_model_output.partition('###')\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{prompt}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{output}\\n')\n",
    "print(dash_line)\n",
    "print(f'PEFT MODEL:\\n{prefix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0dec08ad-5494-4ecf-b54c-152264d5b754",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T13:37:42.160164Z",
     "iopub.status.busy": "2024-03-24T13:37:42.159280Z",
     "iopub.status.idle": "2024-03-24T13:37:58.330685Z",
     "shell.execute_reply": "2024-03-24T13:37:58.328196Z",
     "shell.execute_reply.started": "2024-03-24T13:37:42.160086Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "Instruct: Answer the questions below\n",
      "\n",
      "이준 열사는 자살로 죽은 건가요? \n",
      "제 학원 사회 선생님의 말씀에 의하면 이준 열사는 만국 평화회의 참석을 못하고 심한 감기로 병이 심해져 죽었다고 합니다. 특사들은 돈이 없어 약을 제대로 쓰지 못했다는데, 이 말이 사실인가요?\n",
      "\n",
      "Output:\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "이준 열사는 감기 앓기는 했지만, 자살로 죽은 것은 아닙니다. 당시에는 만국 평화회의 안보협의회에 참석하기 위해 네덜란드로 출국한 이준 열사가 기차 여행을 하면서 육체적, 정신적 지침과 질병에 걸려 병원에 입원했고, 최종적으로 1967년 3월 21일 오후 6시 50분 병원에서 세상을 떠났습니다. 병원 진단서는 아직 발견되지 않았지만, 이위종 밀사의 말에 따르면 이준 열사의 병은 종양이 악화되어 돌아간 것으로 추정됩니다. 따라서 이준 열사는 자살로 죽은 것은 아니며, 감기로 인한 악화로 인해 사망하였습니다. 만약, 어디선가 위와 같은 소문이 나와 다른 정보를 알리고 있다면, 그 대부분은 사실이 아닐 가능성이 높습니다.\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "PEFT MODEL:\n",
      "이준 열사는 자살로 죽은 건가요? \n",
      "제 학원 사회 선생님의 말씀에 의하면 이준 열사는 만는 것이 약을어 약을 제대로 쓰지 못했다는데, 이 말이 사실인가요?\n",
      "\n",
      "이준 열사는 자살로 죽은 건가요? \n",
      "제 학원 사회 선생님의 말씀에 의하면 이준 열사는 만는 것이 약을어 약을 제대로 쓰지 못했다는데, 이 말이 사실인가요?\n",
      "\n",
      "이준 열사는 자살로 죽은 건가요? \n",
      "제 학원 사회 선생님의 말씀에 의하면 이준 열사는 만는 것이 약을어 약을 제대로 쓰지 못했다는데, 이 말이 사실인가요?\n",
      "\n",
      "이준 열사는 자살로 죽은 건가요? \n",
      "제 학원 사회 선생님의 말씀에 의하면 이준 열사는 만는 것이 약을어 약을 제대로 쓰지 못했다는데, 이 말이 사실인가요?\n",
      "\n",
      "이준 열사는 자살로 죽은 건가요?\n",
      "CPU times: user 15.8 s, sys: 169 ms, total: 16 s\n",
      "Wall time: 16.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## 인간 평가 방법\n",
    "from transformers import set_seed\n",
    "seed = 42\n",
    "\n",
    "set_seed(seed)\n",
    "\n",
    "index = 2222\n",
    "instruction = dataset['train'][index]['instruction']\n",
    "output = dataset['train'][index]['output']\n",
    "\n",
    "prompt = f\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\nInstruct: Answer the questions below\\n\\n{instruction}\\n\\nOutput:\\n\"\n",
    "\n",
    "#원래 모델을 사용하여 수행한 것처럼 동일한 입력을 사용하지만 PEFT 모델을 사용하여 추론을 수행\n",
    "peft_model_res = gen(ft_model,prompt,350)\n",
    "peft_model_output = peft_model_res.split('Output:\\n')[1]\n",
    "prefix, success, result = peft_model_output.partition('###')\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{prompt}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{output}\\n')\n",
    "print(dash_line)\n",
    "print(f'PEFT MODEL:\\n{prefix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6566e03-5070-4147-8e69-37f9ada76cfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM_research",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
